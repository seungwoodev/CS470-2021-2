{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS470 Introduction to Artificial Intelligence\n",
    "## Deep Learning Practice \n",
    "#### TA. Minho Sim\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4. Save and restore models\n",
    "\n",
    "#### Topics for this chapter\n",
    " * Saving weights during training\n",
    " * Restoring the saved model\n",
    " * Saving manually\n",
    " * Saving/loading the entire model\n",
    " ---\n",
    "\n",
    "Model progress can be saved during—and after—training. This means that a model can resume where it ended the training and resume at that point. Saving also means you can share your model and others can recreate or reproduce your work. When publishing research models and ML techniques, most machine learning practitioners share:\n",
    "- code to create the model\n",
    "- the trained weights, or parameters, for the model\n",
    "\n",
    "Sharing these data helps others understand how the model works and try it themselves with new or original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "\n",
    "Install and import TensorFlow and dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:55:25.276316Z",
     "start_time": "2021-09-19T11:55:24.303288Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "!pip install -q pyyaml h5py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:55:28.016917Z",
     "start_time": "2021-09-19T11:55:26.046478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get an example dataset\n",
    "\n",
    "To demonstrate how to save and load weights, you'll use the MNIST dataset. To speed up these runs, we will use only the first 1000 examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:55:29.846939Z",
     "start_time": "2021-09-19T11:55:29.358821Z"
    }
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model \n",
    "Start by building a simple sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:55:38.289417Z",
     "start_time": "2021-09-19T11:55:37.593489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define a simple sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "      ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save checkpoints during training (Save weights only)\n",
    "\n",
    "When you have a _trained model_, you don't have to retrain it from the scratch. You can just pick-up training where you left off—in case the training process was interrupted. The callback function in [`tf.keras.callbacks.ModelCheckpoint`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/ModelCheckpoint)  allows us to continually save the model during and at the end of training.\n",
    "\n",
    "#### Checkpoint callback usage\n",
    "Create a tf.keras.callbacks.ModelCheckpoint callback that **_saves weights only_** during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:55:39.179909Z",
     "start_time": "2021-09-19T11:55:39.162914Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ckpt_path_for_t1 = \"checkpoints/training_1/cp.ckpt\"\n",
    "ckpt_dir_for_t1 = os.path.dirname(ckpt_path_for_t1)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_path_for_t1,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:55:42.780932Z",
     "start_time": "2021-09-19T11:55:40.637161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 7ms/step - loss: 1.1208 - accuracy: 0.6950 - val_loss: 0.7080 - val_accuracy: 0.7900\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8820 - val_loss: 0.5283 - val_accuracy: 0.8320\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2836 - accuracy: 0.9260 - val_loss: 0.4722 - val_accuracy: 0.8600\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2061 - accuracy: 0.9580 - val_loss: 0.4512 - val_accuracy: 0.8630\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1842 - accuracy: 0.9550 - val_loss: 0.4256 - val_accuracy: 0.8660\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9770 - val_loss: 0.4272 - val_accuracy: 0.8660\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0862 - accuracy: 0.9890 - val_loss: 0.4242 - val_accuracy: 0.8580\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9920 - val_loss: 0.4052 - val_accuracy: 0.8710\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9970 - val_loss: 0.4075 - val_accuracy: 0.8650\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.8640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24b9a0abfc8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the new callback\n",
    "model.fit(train_images, \n",
    "          train_labels,  \n",
    "          epochs=10,\n",
    "          validation_data=(test_images,test_labels),\n",
    "          callbacks=[cp_callback])  # Pass callback to training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a single collection of TensorFlow checkpoint files that are updated at the end of each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:55:44.507701Z",
     "start_time": "2021-09-19T11:55:44.501698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/training_1\n"
     ]
    }
   ],
   "source": [
    "print(ckpt_dir_for_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restore to the untrained model\n",
    "\n",
    "Now let's rebuild a fresh and untrained model by calling `create_model()`. We can evaluate it on the test set in order to check that it is not trained. An untrained model will have very low accuracy (< 10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:55:45.707854Z",
     "start_time": "2021-09-19T11:55:45.470811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 2.4716 - accuracy: 0.0390\n",
      "Untrained model, accuracy:  3.90%\n"
     ]
    }
   ],
   "source": [
    "# Create a basic model instance\n",
    "new_model = create_model()\n",
    "\n",
    "# Evaluate the model\n",
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this time, let's load the weights from the checkpoint and re-evaluate the test dataset. We can load the weights using `load_weights()`. Since they have the same model architecture, we can share weights despite that it's a different instance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:55:46.787972Z",
     "start_time": "2021-09-19T11:55:46.691043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4052 - accuracy: 0.8710\n",
      "Restored model, accuracy: 87.10%\n"
     ]
    }
   ],
   "source": [
    "# Loads the weights\n",
    "new_model.load_weights(ckpt_path_for_t1)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss,acc = new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "#### Requirement for load weights\n",
    "\n",
    "When restoring a model from weights-only, we must have a model with the **same architecture as the original model**. When we restore weights to the model with different architecture, an error occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:55:47.811898Z",
     "start_time": "2021-09-19T11:55:47.500828Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (100,) and (512,) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22836/1871840260.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdifferent_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdifferent_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdifferent_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt_path_for_t1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2329\u001b[0m     \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_detect_save_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2330\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tf'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2331\u001b[1;33m       \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2332\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2333\u001b[0m         raise NotImplementedError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   1381\u001b[0m         options=options)\n\u001b[0;32m   1382\u001b[0m     base.CheckpointPosition(\n\u001b[1;32m-> 1383\u001b[1;33m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[0m\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m     \u001b[1;31m# Attached dependencies are not attached to the root, so should be restored\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, trackable)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[1;34m(self, checkpoint_position)\u001b[0m\n\u001b[0;32m    979\u001b[0m     restore_ops.extend(\n\u001b[0;32m    980\u001b[0m         current_position.checkpoint.restore_saveables(\n\u001b[1;32m--> 981\u001b[1;33m             tensor_saveables, python_saveables))\n\u001b[0m\u001b[0;32m    982\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[1;34m(self, tensor_saveables, python_saveables)\u001b[0m\n\u001b[0;32m    350\u001b[0m              \"expecting %s\") % (tensor_saveables.keys(), validated_names))\n\u001b[0;32m    351\u001b[0m       new_restore_ops = functional_saver.MultiDeviceSaver(\n\u001b[1;32m--> 352\u001b[1;33m           validated_saveables).restore(self.save_path_tensor, self.options)\n\u001b[0m\u001b[0;32m    353\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestore_op\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    337\u001b[0m       \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_function_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m       \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_after_restore_callbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    321\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaver\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_single_device_savers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m           \u001b[0mrestore_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    114\u001b[0m                                           structured_restored_tensors):\n\u001b[0;32m    115\u001b[0m       restore_ops[saveable.name] = saveable.restore(\n\u001b[1;32m--> 116\u001b[1;33m           restored_tensors, restored_shapes=None)\n\u001b[0m\u001b[0;32m    117\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[0;32m    130\u001b[0m       \u001b[0mrestored_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestored_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m       return resource_variable_ops.shape_safe_assign_variable_handle(\n\u001b[1;32m--> 132\u001b[1;33m           self.handle_op, self._var_shape, restored_tensor)\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mshape_safe_assign_variable_handle\u001b[1;34m(handle, shape, value, name)\u001b[0m\n\u001b[0;32m    307\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[0mvalue_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m   \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m   return gen_resource_variable_ops.assign_variable_op(\n\u001b[0;32m    311\u001b[0m       handle, value_tensor, name=name)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     \"\"\"\n\u001b[0;32m   1160\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (100,) and (512,) are incompatible"
     ]
    }
   ],
   "source": [
    "# Define a different sequential model\n",
    "def different_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(100, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "      ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "different_model = different_model()\n",
    "\n",
    "different_model.load_weights(ckpt_path_for_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "#### Manually save weights\n",
    "\n",
    "You saw how to load the weights into a model. Another way to save the weights is manually saving them by using `Model.save_weights()`. By default, `save_weights` in TensorFlow saves checkpoints format with a .ckpt extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:56:48.986412Z",
     "start_time": "2021-09-19T11:56:48.922554Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights('./checkpoints/manual_checkpoint/cur_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:59:52.201625Z",
     "start_time": "2021-09-19T11:59:52.193622Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T11:59:57.194412Z",
     "start_time": "2021-09-19T11:59:56.964363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model, accuracy: 86.40%\n"
     ]
    }
   ],
   "source": [
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Restore the weights\n",
    "model.load_weights('./checkpoints/manual_checkpoint/cur_weights')\n",
    "\n",
    "# Evaluate the model\n",
    "loss,acc = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "#### Save the entire model \n",
    "\n",
    "Not only weights, the entire model including optimizer and other settings can be saved to a single file. This allows us to export a model and use it without access to the original Python code for creating a model. Since the optimizer-state is recovered, we can resume training from exactly where we left off.\n",
    "\n",
    "We will save the entire model by using HDF5 file extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model as HDF5 file\n",
    "\n",
    "Keras provides a basic save format using the [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T12:00:18.029860Z",
     "start_time": "2021-09-19T12:00:17.075337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1246 - accuracy: 0.6840\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8890\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.9310\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9470\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.9650\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9810\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9930\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9920\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9960\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9980\n"
     ]
    }
   ],
   "source": [
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "# Save the entire model to a HDF5 file\n",
    "save_dir = 'saved_models'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "model.save(os.path.join(save_dir, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T12:00:28.829641Z",
     "start_time": "2021-09-19T12:00:28.793640Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "!ls saved_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "#### Restore the entire model\n",
    "\n",
    "Now, we will load the entire saved model by using `keras.models.load_model()`. We need a path for the saved model as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T12:00:47.868558Z",
     "start_time": "2021-09-19T12:00:47.797707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "new_model = keras.models.load_model(os.path.join(save_dir, 'my_model.h5'))\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "By checking the model's accuracy, we can check whether it is loaded well or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T12:00:50.921070Z",
     "start_time": "2021-09-19T12:00:50.790049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model, accuracy: 86.00%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "This **save the entire model** technique saves following attributes:\n",
    "\n",
    "- The weight values\n",
    "- The model's configuration (architecture)\n",
    "- The optimizer configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T12:00:55.649314Z",
     "start_time": "2021-09-19T12:00:55.639312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.optimizer_v2.adam.Adam object at 0x0000024DC4582E88>\n",
      "<function sparse_categorical_crossentropy at 0x0000024B99197048>\n"
     ]
    }
   ],
   "source": [
    "print(new_model.optimizer)\n",
    "print(new_model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
